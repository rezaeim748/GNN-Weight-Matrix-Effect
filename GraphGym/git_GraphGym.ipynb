{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WJvVi4637nZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6585fa-b494-4671-d95c-e28389d3b797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.0\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.0+cu124 torchaudio-2.5.0+cu124 torchvision-0.20.0+cu124 triton-3.1.0\n",
            "Collecting torch-geometric==2.5.0\n",
            "  Downloading torch_geometric-2.5.0-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (1.16.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (3.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.0) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.0) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.5.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.0) (2025.7.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.5.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.5.0) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric==2.5.0) (4.14.1)\n",
            "Downloading torch_geometric-2.5.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.5.0\n",
            "Collecting deepsnap\n",
            "  Downloading deepsnap-0.2.1.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepsnap) (2.5.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from deepsnap) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepsnap) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (4.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepsnap) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deepsnap) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepsnap) (3.0.2)\n",
            "Building wheels for collected packages: deepsnap\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepsnap: filename=deepsnap-0.2.1-py3-none-any.whl size=76109 sha256=3c93cabb147b2a302c6257d3dda832fc15bf801569df2c1f7272775826257319\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/c6/a8/a1370f928f25f5e7e60bd7e9279dcbae20b1b92f4965021a4e\n",
            "Successfully built deepsnap\n",
            "Installing collected packages: deepsnap\n",
            "Successfully installed deepsnap-0.2.1\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt25cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt25cu124\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.2+pt25cu124\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "!pip install torch==2.5.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install torch-geometric==2.5.0\n",
        "!pip install deepsnap\n",
        "!sed -i 's/from torch._six import container_abcs/import collections.abc as container_abcs/' $(find /usr/local/lib/python3.11/dist-packages/deepsnap -name \"hetero_gnn.py\")\n",
        "from google.colab import drive\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.5.0+cu124.html\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Torch Version:\", torch.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Version:\", torch.version.cuda)\n",
        "!pip list | grep 'torch\\|torch-geometric\\|scatter\\|sparse\\|cluster\\|spline'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIblUNMo0RF_",
        "outputId": "9530145c-9ffc-4fc8-fbca-910c5e3251eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch Version: 2.5.0+cu124\n",
            "CUDA Available: True\n",
            "CUDA Version: 12.4\n",
            "nvidia-cusparse-cu12                  12.3.1.170\n",
            "nvidia-cusparselt-cu12                0.6.2\n",
            "torch                                 2.5.0+cu124\n",
            "torch_cluster                         1.6.3+pt25cu124\n",
            "torch_geometric                       2.5.0\n",
            "torch_scatter                         2.1.2+pt25cu124\n",
            "torch_sparse                          0.6.18+pt25cu124\n",
            "torch_spline_conv                     1.2.2+pt25cu124\n",
            "torchao                               0.10.0\n",
            "torchaudio                            2.5.0+cu124\n",
            "torchdata                             0.11.0\n",
            "torchsummary                          1.5.1\n",
            "torchtune                             0.6.1\n",
            "torchvision                           0.20.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell should be run only once\n",
        "import os\n",
        "\n",
        "file_path = \"/usr/local/lib/python3.11/dist-packages/deepsnap/graph.py\"\n",
        "\n",
        "# Read the file\n",
        "with open(file_path, \"r\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace `data.keys` with `data.keys()` ONLY IF it is not already `data.keys()`\n",
        "content = content.replace(\"data.keys\", \"data.keys()\")\n",
        "\n",
        "# Write back to the file\n",
        "with open(file_path, \"w\") as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"Fixed graph.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ6LfvEWJdA8",
        "outputId": "49e2eeba-b382-4696-e215-a1e054978765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixed graph.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "repo_path = \"/content/drive/MyDrive/GraphGym\"\n",
        "os.chdir(repo_path)\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e .\n",
        "!pip install pytorch_lightning\n",
        "!pip install graphgym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piQrKuzp2QVz",
        "outputId": "232c129a-bd88-4ab6-e3df-9824cd8e540b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting yacs (from -r requirements.txt (line 1))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting tensorboardx (from -r requirements.txt (line 2))\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.5.0+cu124)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: deepsnap in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.2.1)\n",
            "Collecting ogb (from -r requirements.txt (line 6))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.13.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (6.5.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx->-r requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardx->-r requirements.txt (line 2)) (5.29.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r requirements.txt (line 4)) (3.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb->-r requirements.txt (line 6)) (2.5.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->-r requirements.txt (line 6))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (11.3.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (6.4.2)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (26.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (25.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (5.8.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (7.16.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (6.17.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook->-r requirements.txt (line 13)) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->-r requirements.txt (line 13)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->-r requirements.txt (line 13)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->-r requirements.txt (line 13)) (2.19.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->-r requirements.txt (line 13)) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->-r requirements.txt (line 13)) (4.25.0)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb->-r requirements.txt (line 6)) (75.2.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->-r requirements.txt (line 6))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->-r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r requirements.txt (line 4)) (1.20.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->-r requirements.txt (line 13)) (21.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 13)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 13)) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->-r requirements.txt (line 13)) (0.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r requirements.txt (line 4)) (2025.7.14)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook->-r requirements.txt (line 13)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->-r requirements.txt (line 13)) (1.4.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (4.9.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 13)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 13)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->-r requirements.txt (line 13)) (0.26.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 13)) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook->-r requirements.txt (line 13)) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->-r requirements.txt (line 13)) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (0.8.4)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 13)) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 13)) (1.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->notebook->-r requirements.txt (line 13)) (0.2.13)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->-r requirements.txt (line 13)) (1.3.1)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yacs, tensorboardx, littleutils, jedi, outdated, ogb\n",
            "Successfully installed jedi-0.19.2 littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 tensorboardx-2.6.4 yacs-0.1.8\n",
            "Obtaining file:///content/drive/MyDrive/GraphGym\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (0.1.8)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (2.6.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (2.5.0+cu124)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (2.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (2.0.2)\n",
            "Requirement already satisfied: deepsnap in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (0.2.1)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.11/dist-packages (from graphgym==0.4.0) (1.3.6)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym==0.4.0) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym==0.4.0) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym==0.4.0) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym==0.4.0) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym==0.4.0) (2.5.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym==0.4.0) (0.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (4.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym==0.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->graphgym==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx->graphgym==0.4.0) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardx->graphgym==0.4.0) (5.29.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym==0.4.0) (1.16.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym==0.4.0) (3.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym==0.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym==0.4.0) (3.2.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym==0.4.0) (5.9.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->graphgym==0.4.0) (6.0.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb->graphgym==0.4.0) (75.2.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb->graphgym==0.4.0) (0.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb->graphgym==0.4.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb->graphgym==0.4.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb->graphgym==0.4.0) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb->graphgym==0.4.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb->graphgym==0.4.0) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym==0.4.0) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->graphgym==0.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->graphgym==0.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->graphgym==0.4.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->graphgym==0.4.0) (2025.7.14)\n",
            "Installing collected packages: graphgym\n",
            "  Running setup.py develop for graphgym\n",
            "Successfully installed graphgym-0.4.0\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (2.5.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2025.3.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning) (4.14.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.12.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.0-py3-none-any.whl (29 kB)\n",
            "Downloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.15.0 pytorch_lightning-2.5.2 torchmetrics-1.8.0\n",
            "Requirement already satisfied: graphgym in /content/drive/MyDrive/GraphGym (0.4.0)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from graphgym) (0.1.8)\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.11/dist-packages (from graphgym) (2.6.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from graphgym) (2.5.0+cu124)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (from graphgym) (2.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from graphgym) (3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphgym) (2.0.2)\n",
            "Requirement already satisfied: deepsnap in /usr/local/lib/python3.11/dist-packages (from graphgym) (0.2.1)\n",
            "Requirement already satisfied: ogb in /usr/local/lib/python3.11/dist-packages (from graphgym) (1.3.6)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym) (2.5.0)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ogb->graphgym) (0.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (4.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->graphgym) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->graphgym) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardx->graphgym) (25.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardx->graphgym) (5.29.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym) (1.16.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym) (3.12.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym) (3.2.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->graphgym) (5.9.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->graphgym) (6.0.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb->graphgym) (75.2.0)\n",
            "Requirement already satisfied: littleutils in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb->graphgym) (0.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb->graphgym) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb->graphgym) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb->graphgym) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb->graphgym) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb->graphgym) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->graphgym) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->graphgym) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->graphgym) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->graphgym) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->graphgym) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd run\n",
        "# !bash run_batch.sh # run a batch of experiments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhJpqIZm-yeF",
        "outputId": "2ff1f67c-cfdd-439f-ea94-016a794ec5f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GraphGym/run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Mount Google Drive (only needed in Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the paths\n",
        "base_dir = \"/content/drive/MyDrive/GraphGym/run\"\n",
        "configs_dir = os.path.join(base_dir, \"configs/PubMed_1_grid_example_modified\")  # Path to YAML configuration files\n",
        "results_dir = os.path.join(base_dir, \"results/PubMed_1_grid_example_modified\")  # Path to results folders\n",
        "\n",
        "# Get all YAML configuration filenames (remove \".yaml\" to match experiment folder names)\n",
        "all_configurations = {f[:-5] for f in os.listdir(configs_dir) if f.endswith(\".yaml\")}\n",
        "\n",
        "# Get all completed experiment folder names\n",
        "completed_experiments = {f for f in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, f))}\n",
        "\n",
        "# Find configurations that do not have a corresponding result folder\n",
        "undone_configurations = all_configurations - completed_experiments\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Completed Experiments ({len(completed_experiments)}):\")\n",
        "for exp in sorted(completed_experiments):\n",
        "    print(exp)\n",
        "\n",
        "print(f\"\\n❌ Undone Configurations ({len(undone_configurations)}):\")\n",
        "for config in sorted(undone_configurations):\n",
        "    print(config)\n",
        "\n",
        "# Optional: Save the undone configurations to a file\n",
        "undone_file = os.path.join(base_dir, \"undone_experiments.txt\")\n",
        "with open(undone_file, \"w\") as f:\n",
        "    for config in sorted(undone_configurations):\n",
        "        f.write(config + \"\\n\")\n",
        "\n",
        "print(f\"\\n📄 A list of undone configurations has been saved to: {undone_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "HXMaBWfiVwk8",
        "outputId": "ecbdf3a2-fe63-429a-8152-e770e99dded5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/GraphGym/run/results/PubMed_1_grid_example_modified'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2916345801.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Get all completed experiment folder names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcompleted_experiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Find configurations that do not have a corresponding result folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/GraphGym/run/results/PubMed_1_grid_example_modified'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GraphGym\n",
        "from graphgym.utils.agg_runs import agg_runs\n",
        "import argparse\n",
        "from graphgym.utils.agg_runs import agg_batch\n",
        "# agg_runs(\"run/results/PubMed_1_grid_example_modified\", \"auto\")\n",
        "def parse_args():\n",
        "    \"\"\"Parses the arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='Train a classification model')\n",
        "    parser.add_argument('--dir', dest='dir', help='Dir for batch of results',\n",
        "                        required=True, type=str)\n",
        "    parser.add_argument('--metric', dest='metric',\n",
        "                        help='metric to select best epoch', required=False,\n",
        "                        type=str, default='auto')\n",
        "    return parser.parse_args()\n",
        "\n",
        "agg_batch(\"run/results/Cora_grid_Cora_Metrics\", \"accuracy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOlAzxAkpLiM",
        "outputId": "811019fd-67bc-4717-d882-6179a604eaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'GraphGym'\n",
            "/content/drive/MyDrive/GraphGym\n",
            "Results aggregated across models saved in run/results/Cora_grid_Cora_Metrics/agg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import yaml\n",
        "\n",
        "def load_yaml(filepath):\n",
        "    \"\"\"Load YAML file.\"\"\"\n",
        "    with open(filepath, \"r\") as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "def save_yaml(data, filepath):\n",
        "    \"\"\"Save YAML file.\"\"\"\n",
        "    with open(filepath, \"w\") as file:\n",
        "        yaml.safe_dump(data, file)\n",
        "\n",
        "# Path to your YAML file\n",
        "yaml_path = \"/content/drive/MyDrive/GraphGym/run/configs/example.yaml\"\n",
        "\n",
        "# Load YAML\n",
        "config_data = load_yaml(yaml_path)\n",
        "\n",
        "# Modify the `name` parameter inside `dataset`\n",
        "config_data[\"dataset\"][\"name\"] = \"Cora\"  # Change 'Karate' to 'Cora'\n",
        "\n",
        "# Save back to YAML\n",
        "save_yaml(config_data, yaml_path)\n",
        "\n",
        "print(f\"Updated YAML file: {yaml_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi21yMhWE-us",
        "outputId": "adc69a73-7d44-4c17-f553-632df68e88dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated YAML file: /content/drive/MyDrive/GraphGym/run/configs/example.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define original and new file paths\n",
        "original_yaml_path = \"/content/drive/MyDrive/GraphGym/run/configs/example.yaml\"\n",
        "new_yaml_path = \"/content/drive/MyDrive/GraphGym/run/configs/example_modified.yaml\"\n",
        "\n",
        "# Copy the modified file to a new file\n",
        "shutil.copy(original_yaml_path, new_yaml_path)\n",
        "\n",
        "print(f\"Modified YAML file saved as: {new_yaml_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsrzLaBAhZjQ",
        "outputId": "8bb7c3c0-4075-4c61-e1d1-46a143732bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified YAML file saved as: /content/drive/MyDrive/GraphGym/run/configs/example_modified.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/GraphGym/graphgym/contrib/layer/lightgcnconv.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLpAZy18cA_w",
        "outputId": "bf9624c9-3b93-467c-e438-21bf517d037e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/contrib/layer/lightgcnconv.py\", line 44, in <module>\n",
            "    register_layer('lightgcnconv', LightGCNConv)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/register.py\", line 76, in register_layer\n",
            "    return register_base(layer_dict, key, module)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/register.py\", line 37, in register_base\n",
            "    raise KeyError(f\"Module with '{key}' already defined\")\n",
            "KeyError: \"Module with 'lightgcnconv' already defined\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/GraphGym/graphgym/contrib/loader/dblp_loader.py"
      ],
      "metadata": {
        "id": "472HzJoMjJU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --cfg /content/drive/MyDrive/GraphGym/run/configs/example_modified.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oKXmoSk4XHs",
        "outputId": "694ca3cd-b211-4a6b-87d6-d10b56297164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Mem: [2]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 2\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 3.001s, Before split: 0.0003762s, Split: 0.0003536s, After split: 0.0002942s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=1433\n",
            "    Total: dim_out=1433\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=1433, out_features=256, bias=False)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNStackStage(\n",
            "    (layer0): GeneralLayer(\n",
            "      (layer): GCNConv(\n",
            "        (model): GCNConv(256, 256)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "    (layer1): GeneralLayer(\n",
            "      (layer): GCNConv(\n",
            "        (model): GCNConv(256, 256)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (1): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): Linear(\n",
            "          (model): Linear(in_features=256, out_features=7, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: Cora\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: add\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: True\n",
            "  clear_feature: True\n",
            "  dim_inner: 256\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: gcnconv\n",
            "  layers_mp: 2\n",
            "  layers_post_mp: 1\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: stack\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 100\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/example_modified\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/example_modified/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 1433\n",
            "  dim_out: 7\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 501256\n",
            "Start from epoch 0\n",
            "train: {'epoch': 0, 'eta': 54.7649, 'loss': 1.9765, 'lr': 0.01, 'params': 501256, 'time_iter': 0.5532, 'accuracy': 0.1025, 'precision': 0.0913, 'recall': 0.0918, 'f1': 0.0813, 'auc': 0.0}\n",
            "val: {'epoch': 0, 'loss': 1.4151, 'lr': 0, 'params': 501256, 'time_iter': 0.0276, 'accuracy': 0.8081, 'precision': 0.8055, 'recall': 0.7952, 'f1': 0.7864, 'auc': 0.0}\n",
            "train: {'epoch': 1, 'eta': 27.9981, 'loss': 1.3469, 'lr': 0.01, 'params': 501256, 'time_iter': 0.0182, 'accuracy': 0.8536, 'precision': 0.8361, 'recall': 0.8603, 'f1': 0.8463, 'auc': 0.0}\n",
            "train: {'epoch': 2, 'eta': 19.0565, 'loss': 0.9956, 'lr': 0.01, 'params': 501256, 'time_iter': 0.018, 'accuracy': 0.9063, 'precision': 0.9025, 'recall': 0.8935, 'f1': 0.8974, 'auc': 0.0}\n",
            "train: {'epoch': 3, 'eta': 14.7256, 'loss': 0.8332, 'lr': 0.01, 'params': 501256, 'time_iter': 0.0242, 'accuracy': 0.9211, 'precision': 0.9182, 'recall': 0.9107, 'f1': 0.9138, 'auc': 0.0}\n",
            "train: {'epoch': 4, 'eta': 12.0068, 'loss': 0.7345, 'lr': 0.01, 'params': 501256, 'time_iter': 0.0184, 'accuracy': 0.9312, 'precision': 0.9287, 'recall': 0.9205, 'f1': 0.9243, 'auc': 0.0}\n",
            "train: {'epoch': 5, 'eta': 10.1862, 'loss': 0.6571, 'lr': 0.0099, 'params': 501256, 'time_iter': 0.0182, 'accuracy': 0.9381, 'precision': 0.9347, 'recall': 0.9275, 'f1': 0.9309, 'auc': 0.0}\n",
            "train: {'epoch': 6, 'eta': 8.8962, 'loss': 0.5908, 'lr': 0.0099, 'params': 501256, 'time_iter': 0.0194, 'accuracy': 0.94, 'precision': 0.9369, 'recall': 0.9291, 'f1': 0.9328, 'auc': 0.0}\n",
            "train: {'epoch': 7, 'eta': 7.8989, 'loss': 0.5318, 'lr': 0.0099, 'params': 501256, 'time_iter': 0.0173, 'accuracy': 0.9441, 'precision': 0.9409, 'recall': 0.9344, 'f1': 0.9375, 'auc': 0.0}\n",
            "train: {'epoch': 8, 'eta': 7.1307, 'loss': 0.4774, 'lr': 0.0098, 'params': 501256, 'time_iter': 0.0184, 'accuracy': 0.9488, 'precision': 0.9466, 'recall': 0.9387, 'f1': 0.9424, 'auc': 0.0}\n",
            "train: {'epoch': 9, 'eta': 6.5051, 'loss': 0.4279, 'lr': 0.0098, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.952, 'precision': 0.9514, 'recall': 0.9424, 'f1': 0.9467, 'auc': 0.0}\n",
            "train: {'epoch': 10, 'eta': 5.9883, 'loss': 0.3833, 'lr': 0.0098, 'params': 501256, 'time_iter': 0.0173, 'accuracy': 0.9557, 'precision': 0.9541, 'recall': 0.948, 'f1': 0.9508, 'auc': 0.0}\n",
            "train: {'epoch': 11, 'eta': 5.5625, 'loss': 0.3433, 'lr': 0.0097, 'params': 501256, 'time_iter': 0.0184, 'accuracy': 0.9608, 'precision': 0.9595, 'recall': 0.9538, 'f1': 0.9564, 'auc': 0.0}\n",
            "train: {'epoch': 12, 'eta': 5.1941, 'loss': 0.3073, 'lr': 0.0096, 'params': 501256, 'time_iter': 0.0176, 'accuracy': 0.9672, 'precision': 0.9643, 'recall': 0.9617, 'f1': 0.9629, 'auc': 0.0}\n",
            "train: {'epoch': 13, 'eta': 4.8769, 'loss': 0.2756, 'lr': 0.0096, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9718, 'precision': 0.9708, 'recall': 0.9665, 'f1': 0.9686, 'auc': 0.0}\n",
            "train: {'epoch': 14, 'eta': 4.6031, 'loss': 0.2478, 'lr': 0.0095, 'params': 501256, 'time_iter': 0.0184, 'accuracy': 0.976, 'precision': 0.9742, 'recall': 0.9717, 'f1': 0.9729, 'auc': 0.0}\n",
            "train: {'epoch': 15, 'eta': 4.3832, 'loss': 0.2234, 'lr': 0.0095, 'params': 501256, 'time_iter': 0.0226, 'accuracy': 0.9769, 'precision': 0.9764, 'recall': 0.9739, 'f1': 0.9751, 'auc': 0.0}\n",
            "train: {'epoch': 16, 'eta': 4.1657, 'loss': 0.2022, 'lr': 0.0094, 'params': 501256, 'time_iter': 0.0183, 'accuracy': 0.9774, 'precision': 0.9775, 'recall': 0.9741, 'f1': 0.9757, 'auc': 0.0}\n",
            "train: {'epoch': 17, 'eta': 3.9688, 'loss': 0.184, 'lr': 0.0093, 'params': 501256, 'time_iter': 0.018, 'accuracy': 0.9797, 'precision': 0.9799, 'recall': 0.9768, 'f1': 0.9782, 'auc': 0.0}\n",
            "train: {'epoch': 18, 'eta': 3.7887, 'loss': 0.1668, 'lr': 0.0092, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9825, 'precision': 0.9826, 'recall': 0.9786, 'f1': 0.9805, 'auc': 0.0}\n",
            "train: {'epoch': 19, 'eta': 3.6244, 'loss': 0.152, 'lr': 0.0091, 'params': 501256, 'time_iter': 0.0174, 'accuracy': 0.9834, 'precision': 0.9841, 'recall': 0.9797, 'f1': 0.9818, 'auc': 0.0}\n",
            "val: {'epoch': 19, 'loss': 0.4908, 'lr': 0, 'params': 501256, 'time_iter': 0.014, 'accuracy': 0.8598, 'precision': 0.8546, 'recall': 0.8392, 'f1': 0.8458, 'auc': 0.0}\n",
            "train: {'epoch': 20, 'eta': 3.4792, 'loss': 0.14, 'lr': 0.009, 'params': 501256, 'time_iter': 0.0188, 'accuracy': 0.9857, 'precision': 0.9862, 'recall': 0.9826, 'f1': 0.9844, 'auc': 0.0}\n",
            "train: {'epoch': 21, 'eta': 3.3487, 'loss': 0.1282, 'lr': 0.009, 'params': 501256, 'time_iter': 0.0197, 'accuracy': 0.988, 'precision': 0.9878, 'recall': 0.9854, 'f1': 0.9865, 'auc': 0.0}\n",
            "train: {'epoch': 22, 'eta': 3.2217, 'loss': 0.1182, 'lr': 0.0089, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9894, 'precision': 0.989, 'recall': 0.9876, 'f1': 0.9883, 'auc': 0.0}\n",
            "train: {'epoch': 23, 'eta': 3.1033, 'loss': 0.1087, 'lr': 0.0088, 'params': 501256, 'time_iter': 0.0177, 'accuracy': 0.9894, 'precision': 0.988, 'recall': 0.9878, 'f1': 0.9878, 'auc': 0.0}\n",
            "train: {'epoch': 24, 'eta': 2.9933, 'loss': 0.1018, 'lr': 0.0086, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9908, 'precision': 0.9909, 'recall': 0.9888, 'f1': 0.9898, 'auc': 0.0}\n",
            "train: {'epoch': 25, 'eta': 2.8906, 'loss': 0.0938, 'lr': 0.0085, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9903, 'precision': 0.9898, 'recall': 0.9888, 'f1': 0.9893, 'auc': 0.0}\n",
            "train: {'epoch': 26, 'eta': 2.7936, 'loss': 0.0889, 'lr': 0.0084, 'params': 501256, 'time_iter': 0.0176, 'accuracy': 0.9912, 'precision': 0.993, 'recall': 0.9892, 'f1': 0.991, 'auc': 0.0}\n",
            "train: {'epoch': 27, 'eta': 2.7023, 'loss': 0.0843, 'lr': 0.0083, 'params': 501256, 'time_iter': 0.0177, 'accuracy': 0.9922, 'precision': 0.9943, 'recall': 0.9901, 'f1': 0.9922, 'auc': 0.0}\n",
            "train: {'epoch': 28, 'eta': 2.6162, 'loss': 0.0788, 'lr': 0.0082, 'params': 501256, 'time_iter': 0.0177, 'accuracy': 0.9931, 'precision': 0.9937, 'recall': 0.9927, 'f1': 0.9932, 'auc': 0.0}\n",
            "train: {'epoch': 29, 'eta': 2.5352, 'loss': 0.0765, 'lr': 0.0081, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9908, 'precision': 0.9901, 'recall': 0.9911, 'f1': 0.9906, 'auc': 0.0}\n",
            "train: {'epoch': 30, 'eta': 2.4581, 'loss': 0.0695, 'lr': 0.0079, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9931, 'precision': 0.9941, 'recall': 0.9924, 'f1': 0.9932, 'auc': 0.0}\n",
            "train: {'epoch': 31, 'eta': 2.3976, 'loss': 0.0687, 'lr': 0.0078, 'params': 501256, 'time_iter': 0.0239, 'accuracy': 0.9922, 'precision': 0.9925, 'recall': 0.9926, 'f1': 0.9925, 'auc': 0.0}\n",
            "train: {'epoch': 32, 'eta': 2.3276, 'loss': 0.0658, 'lr': 0.0077, 'params': 501256, 'time_iter': 0.0181, 'accuracy': 0.994, 'precision': 0.9947, 'recall': 0.9928, 'f1': 0.9937, 'auc': 0.0}\n",
            "train: {'epoch': 33, 'eta': 2.26, 'loss': 0.0646, 'lr': 0.0075, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9922, 'precision': 0.9932, 'recall': 0.9916, 'f1': 0.9924, 'auc': 0.0}\n",
            "train: {'epoch': 34, 'eta': 2.1949, 'loss': 0.0644, 'lr': 0.0074, 'params': 501256, 'time_iter': 0.0176, 'accuracy': 0.9917, 'precision': 0.9918, 'recall': 0.9924, 'f1': 0.9921, 'auc': 0.0}\n",
            "train: {'epoch': 35, 'eta': 2.1433, 'loss': 0.0595, 'lr': 0.0073, 'params': 501256, 'time_iter': 0.0238, 'accuracy': 0.9935, 'precision': 0.994, 'recall': 0.9933, 'f1': 0.9936, 'auc': 0.0}\n",
            "train: {'epoch': 36, 'eta': 2.0847, 'loss': 0.0593, 'lr': 0.0071, 'params': 501256, 'time_iter': 0.0188, 'accuracy': 0.9926, 'precision': 0.9927, 'recall': 0.9925, 'f1': 0.9926, 'auc': 0.0}\n",
            "train: {'epoch': 37, 'eta': 2.0288, 'loss': 0.0588, 'lr': 0.007, 'params': 501256, 'time_iter': 0.0191, 'accuracy': 0.9908, 'precision': 0.9912, 'recall': 0.9903, 'f1': 0.9907, 'auc': 0.0}\n",
            "train: {'epoch': 38, 'eta': 1.9722, 'loss': 0.0535, 'lr': 0.0068, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9931, 'precision': 0.9941, 'recall': 0.992, 'f1': 0.993, 'auc': 0.0}\n",
            "train: {'epoch': 39, 'eta': 1.92, 'loss': 0.0539, 'lr': 0.0067, 'params': 501256, 'time_iter': 0.0191, 'accuracy': 0.9935, 'precision': 0.994, 'recall': 0.9931, 'f1': 0.9936, 'auc': 0.0}\n",
            "val: {'epoch': 39, 'loss': 0.562, 'lr': 0, 'params': 501256, 'time_iter': 0.0137, 'accuracy': 0.8506, 'precision': 0.8531, 'recall': 0.8215, 'f1': 0.835, 'auc': 0.0}\n",
            "train: {'epoch': 40, 'eta': 1.8678, 'loss': 0.0512, 'lr': 0.0065, 'params': 501256, 'time_iter': 0.018, 'accuracy': 0.9935, 'precision': 0.9937, 'recall': 0.9934, 'f1': 0.9936, 'auc': 0.0}\n",
            "train: {'epoch': 41, 'eta': 1.8174, 'loss': 0.0487, 'lr': 0.0064, 'params': 501256, 'time_iter': 0.0181, 'accuracy': 0.994, 'precision': 0.9937, 'recall': 0.9943, 'f1': 0.994, 'auc': 0.0}\n",
            "train: {'epoch': 42, 'eta': 1.7687, 'loss': 0.0474, 'lr': 0.0062, 'params': 501256, 'time_iter': 0.0182, 'accuracy': 0.9926, 'precision': 0.9925, 'recall': 0.9913, 'f1': 0.9919, 'auc': 0.0}\n",
            "train: {'epoch': 43, 'eta': 1.7217, 'loss': 0.0482, 'lr': 0.0061, 'params': 501256, 'time_iter': 0.0185, 'accuracy': 0.9935, 'precision': 0.9935, 'recall': 0.9938, 'f1': 0.9936, 'auc': 0.0}\n",
            "train: {'epoch': 44, 'eta': 1.6745, 'loss': 0.0558, 'lr': 0.0059, 'params': 501256, 'time_iter': 0.0172, 'accuracy': 0.9898, 'precision': 0.9904, 'recall': 0.9869, 'f1': 0.9886, 'auc': 0.0}\n",
            "train: {'epoch': 45, 'eta': 1.6292, 'loss': 0.0936, 'lr': 0.0058, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9825, 'precision': 0.9766, 'recall': 0.9807, 'f1': 0.9779, 'auc': 0.0}\n",
            "train: {'epoch': 46, 'eta': 1.5847, 'loss': 0.1044, 'lr': 0.0056, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9691, 'precision': 0.9683, 'recall': 0.9684, 'f1': 0.9673, 'auc': 0.0}\n",
            "train: {'epoch': 47, 'eta': 1.5453, 'loss': 0.1002, 'lr': 0.0055, 'params': 501256, 'time_iter': 0.0211, 'accuracy': 0.9714, 'precision': 0.9724, 'recall': 0.9634, 'f1': 0.9666, 'auc': 0.0}\n",
            "train: {'epoch': 48, 'eta': 1.5029, 'loss': 0.0769, 'lr': 0.0053, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9848, 'precision': 0.9845, 'recall': 0.9805, 'f1': 0.9824, 'auc': 0.0}\n",
            "train: {'epoch': 49, 'eta': 1.4617, 'loss': 0.0745, 'lr': 0.0052, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9852, 'precision': 0.9826, 'recall': 0.9828, 'f1': 0.9826, 'auc': 0.0}\n",
            "train: {'epoch': 50, 'eta': 1.4214, 'loss': 0.0759, 'lr': 0.005, 'params': 501256, 'time_iter': 0.0176, 'accuracy': 0.9829, 'precision': 0.9794, 'recall': 0.9812, 'f1': 0.9802, 'auc': 0.0}\n",
            "train: {'epoch': 51, 'eta': 1.3825, 'loss': 0.0729, 'lr': 0.0048, 'params': 501256, 'time_iter': 0.0183, 'accuracy': 0.9861, 'precision': 0.9839, 'recall': 0.9851, 'f1': 0.9844, 'auc': 0.0}\n",
            "train: {'epoch': 52, 'eta': 1.3459, 'loss': 0.0653, 'lr': 0.0047, 'params': 501256, 'time_iter': 0.02, 'accuracy': 0.9903, 'precision': 0.988, 'recall': 0.9899, 'f1': 0.9889, 'auc': 0.0}\n",
            "train: {'epoch': 53, 'eta': 1.3091, 'loss': 0.0613, 'lr': 0.0045, 'params': 501256, 'time_iter': 0.0191, 'accuracy': 0.9885, 'precision': 0.9862, 'recall': 0.9861, 'f1': 0.9861, 'auc': 0.0}\n",
            "train: {'epoch': 54, 'eta': 1.2716, 'loss': 0.0574, 'lr': 0.0044, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9894, 'precision': 0.9891, 'recall': 0.9865, 'f1': 0.9877, 'auc': 0.0}\n",
            "train: {'epoch': 55, 'eta': 1.2352, 'loss': 0.0552, 'lr': 0.0042, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9908, 'precision': 0.9901, 'recall': 0.9883, 'f1': 0.9892, 'auc': 0.0}\n",
            "train: {'epoch': 56, 'eta': 1.1992, 'loss': 0.0531, 'lr': 0.0041, 'params': 501256, 'time_iter': 0.0176, 'accuracy': 0.9912, 'precision': 0.9906, 'recall': 0.9886, 'f1': 0.9896, 'auc': 0.0}\n",
            "train: {'epoch': 57, 'eta': 1.1636, 'loss': 0.0506, 'lr': 0.0039, 'params': 501256, 'time_iter': 0.0173, 'accuracy': 0.9917, 'precision': 0.9909, 'recall': 0.99, 'f1': 0.9904, 'auc': 0.0}\n",
            "train: {'epoch': 58, 'eta': 1.1288, 'loss': 0.0487, 'lr': 0.0038, 'params': 501256, 'time_iter': 0.0174, 'accuracy': 0.9926, 'precision': 0.9911, 'recall': 0.9916, 'f1': 0.9913, 'auc': 0.0}\n",
            "train: {'epoch': 59, 'eta': 1.0952, 'loss': 0.0472, 'lr': 0.0036, 'params': 501256, 'time_iter': 0.0184, 'accuracy': 0.9926, 'precision': 0.9917, 'recall': 0.9909, 'f1': 0.9913, 'auc': 0.0}\n",
            "val: {'epoch': 59, 'loss': 0.5746, 'lr': 0, 'params': 501256, 'time_iter': 0.0135, 'accuracy': 0.8561, 'precision': 0.8528, 'recall': 0.8365, 'f1': 0.8435, 'auc': 0.0}\n",
            "train: {'epoch': 60, 'eta': 1.0618, 'loss': 0.0461, 'lr': 0.0035, 'params': 501256, 'time_iter': 0.018, 'accuracy': 0.9922, 'precision': 0.9918, 'recall': 0.9909, 'f1': 0.9913, 'auc': 0.0}\n",
            "train: {'epoch': 61, 'eta': 1.0286, 'loss': 0.0445, 'lr': 0.0033, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.994, 'precision': 0.993, 'recall': 0.993, 'f1': 0.993, 'auc': 0.0}\n",
            "train: {'epoch': 62, 'eta': 0.9975, 'loss': 0.0428, 'lr': 0.0032, 'params': 501256, 'time_iter': 0.0202, 'accuracy': 0.9954, 'precision': 0.995, 'recall': 0.9948, 'f1': 0.9949, 'auc': 0.0}\n",
            "train: {'epoch': 63, 'eta': 0.9668, 'loss': 0.0413, 'lr': 0.003, 'params': 501256, 'time_iter': 0.0203, 'accuracy': 0.9954, 'precision': 0.9954, 'recall': 0.9951, 'f1': 0.9952, 'auc': 0.0}\n",
            "train: {'epoch': 64, 'eta': 0.9352, 'loss': 0.0403, 'lr': 0.0029, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9954, 'precision': 0.9955, 'recall': 0.9945, 'f1': 0.995, 'auc': 0.0}\n",
            "train: {'epoch': 65, 'eta': 0.9042, 'loss': 0.0394, 'lr': 0.0027, 'params': 501256, 'time_iter': 0.0185, 'accuracy': 0.9954, 'precision': 0.9953, 'recall': 0.9937, 'f1': 0.9945, 'auc': 0.0}\n",
            "train: {'epoch': 66, 'eta': 0.8731, 'loss': 0.0385, 'lr': 0.0026, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9958, 'precision': 0.9959, 'recall': 0.9943, 'f1': 0.9951, 'auc': 0.0}\n",
            "train: {'epoch': 67, 'eta': 0.8424, 'loss': 0.0376, 'lr': 0.0025, 'params': 501256, 'time_iter': 0.0175, 'accuracy': 0.9968, 'precision': 0.9969, 'recall': 0.9962, 'f1': 0.9965, 'auc': 0.0}\n",
            "train: {'epoch': 68, 'eta': 0.8142, 'loss': 0.0367, 'lr': 0.0023, 'params': 501256, 'time_iter': 0.0222, 'accuracy': 0.9963, 'precision': 0.996, 'recall': 0.9963, 'f1': 0.9961, 'auc': 0.0}\n",
            "train: {'epoch': 69, 'eta': 0.7849, 'loss': 0.036, 'lr': 0.0022, 'params': 501256, 'time_iter': 0.019, 'accuracy': 0.9963, 'precision': 0.996, 'recall': 0.9963, 'f1': 0.9961, 'auc': 0.0}\n",
            "train: {'epoch': 70, 'eta': 0.756, 'loss': 0.0354, 'lr': 0.0021, 'params': 501256, 'time_iter': 0.0195, 'accuracy': 0.9972, 'precision': 0.997, 'recall': 0.9971, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 71, 'eta': 0.7269, 'loss': 0.0348, 'lr': 0.0019, 'params': 501256, 'time_iter': 0.0184, 'accuracy': 0.9972, 'precision': 0.997, 'recall': 0.9971, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 72, 'eta': 0.6981, 'loss': 0.0342, 'lr': 0.0018, 'params': 501256, 'time_iter': 0.0183, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 73, 'eta': 0.6694, 'loss': 0.0337, 'lr': 0.0017, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 74, 'eta': 0.6411, 'loss': 0.0332, 'lr': 0.0016, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 75, 'eta': 0.6134, 'loss': 0.0328, 'lr': 0.0015, 'params': 501256, 'time_iter': 0.0194, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 76, 'eta': 0.5856, 'loss': 0.0324, 'lr': 0.0014, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9972, 'precision': 0.9968, 'recall': 0.9973, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 77, 'eta': 0.558, 'loss': 0.032, 'lr': 0.0012, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9972, 'precision': 0.997, 'recall': 0.9971, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 78, 'eta': 0.5311, 'loss': 0.0317, 'lr': 0.0011, 'params': 501256, 'time_iter': 0.0197, 'accuracy': 0.9972, 'precision': 0.997, 'recall': 0.9971, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 79, 'eta': 0.504, 'loss': 0.0314, 'lr': 0.001, 'params': 501256, 'time_iter': 0.0181, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "val: {'epoch': 79, 'loss': 0.6367, 'lr': 0, 'params': 501256, 'time_iter': 0.0135, 'accuracy': 0.845, 'precision': 0.8367, 'recall': 0.8287, 'f1': 0.8318, 'auc': 0.0}\n",
            "train: {'epoch': 80, 'eta': 0.478, 'loss': 0.0311, 'lr': 0.001, 'params': 501256, 'time_iter': 0.0217, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 81, 'eta': 0.4527, 'loss': 0.0308, 'lr': 0.0009, 'params': 501256, 'time_iter': 0.0245, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 82, 'eta': 0.4263, 'loss': 0.0306, 'lr': 0.0008, 'params': 501256, 'time_iter': 0.019, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 83, 'eta': 0.3999, 'loss': 0.0304, 'lr': 0.0007, 'params': 501256, 'time_iter': 0.0185, 'accuracy': 0.9972, 'precision': 0.9973, 'recall': 0.9968, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 84, 'eta': 0.3737, 'loss': 0.0302, 'lr': 0.0006, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9972, 'precision': 0.997, 'recall': 0.9971, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 85, 'eta': 0.3476, 'loss': 0.03, 'lr': 0.0005, 'params': 501256, 'time_iter': 0.0177, 'accuracy': 0.9972, 'precision': 0.997, 'recall': 0.9971, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 86, 'eta': 0.3217, 'loss': 0.0298, 'lr': 0.0005, 'params': 501256, 'time_iter': 0.0177, 'accuracy': 0.9972, 'precision': 0.9968, 'recall': 0.9973, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 87, 'eta': 0.296, 'loss': 0.0297, 'lr': 0.0004, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9972, 'precision': 0.9968, 'recall': 0.9973, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 88, 'eta': 0.2705, 'loss': 0.0296, 'lr': 0.0004, 'params': 501256, 'time_iter': 0.0174, 'accuracy': 0.9972, 'precision': 0.9968, 'recall': 0.9973, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 89, 'eta': 0.2451, 'loss': 0.0295, 'lr': 0.0003, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9972, 'precision': 0.9968, 'recall': 0.9973, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 90, 'eta': 0.22, 'loss': 0.0294, 'lr': 0.0002, 'params': 501256, 'time_iter': 0.018, 'accuracy': 0.9972, 'precision': 0.9968, 'recall': 0.9973, 'f1': 0.9971, 'auc': 0.0}\n",
            "train: {'epoch': 91, 'eta': 0.195, 'loss': 0.0294, 'lr': 0.0002, 'params': 501256, 'time_iter': 0.0178, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 92, 'eta': 0.1701, 'loss': 0.0293, 'lr': 0.0002, 'params': 501256, 'time_iter': 0.0181, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 93, 'eta': 0.1454, 'loss': 0.0293, 'lr': 0.0001, 'params': 501256, 'time_iter': 0.018, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 94, 'eta': 0.1209, 'loss': 0.0292, 'lr': 0.0001, 'params': 501256, 'time_iter': 0.0181, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 95, 'eta': 0.0964, 'loss': 0.0292, 'lr': 0.0001, 'params': 501256, 'time_iter': 0.0179, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 96, 'eta': 0.0722, 'loss': 0.0292, 'lr': 0.0, 'params': 501256, 'time_iter': 0.0201, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 97, 'eta': 0.048, 'loss': 0.0292, 'lr': 0.0, 'params': 501256, 'time_iter': 0.0187, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 98, 'eta': 0.024, 'loss': 0.0292, 'lr': 0.0, 'params': 501256, 'time_iter': 0.0188, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "train: {'epoch': 99, 'eta': 0.0, 'loss': 0.0292, 'lr': 0.0, 'params': 501256, 'time_iter': 0.0183, 'accuracy': 0.9972, 'precision': 0.9971, 'recall': 0.997, 'f1': 0.997, 'auc': 0.0}\n",
            "val: {'epoch': 99, 'loss': 0.656, 'lr': 0, 'params': 501256, 'time_iter': 0.0176, 'accuracy': 0.845, 'precision': 0.8312, 'recall': 0.8298, 'f1': 0.8297, 'auc': 0.0}\n",
            "Task done, results saved in results/example_modified\n",
            "0\n",
            "{'epoch': 0, 'eta': 54.7649, 'loss': 1.9765, 'lr': 0.01, 'params': 501256, 'time_iter': 0.5532, 'accuracy': 0.1025, 'precision': 0.0913, 'recall': 0.0918, 'f1': 0.0813, 'auc': 0.0}\n",
            "{'epoch': 0, 'loss': 1.4151, 'lr': 0, 'params': 501256, 'time_iter': 0.0276, 'accuracy': 0.8081, 'precision': 0.8055, 'recall': 0.7952, 'f1': 0.7864, 'auc': 0.0}\n",
            "Results aggregated across runs saved in results/example_modified/agg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/\\r$//' /content/drive/MyDrive/GraphGym/run/run_batch_example.sh\n",
        "!bash /content/drive/MyDrive/GraphGym/run/run_batch_example.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5n6VVh3XslF",
        "outputId": "2d04dd7f-ec30-4851-8401-852bf1c444a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 225311\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 121])\n",
            "GPU Mem: [830]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 830\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "After propagation: torch.Size([7650, 121])\n",
            "Before propagation: torch.Size([7650, 242])\n",
            "After propagation: torch.Size([7650, 242])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x484 and 363x363)\n",
            "GPU Mem: [1050]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 1050\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 9.686s, Before split: 0.005s, Split: 0.003212s, After split: 0.0006588s\n",
            "GPU Mem: [1050]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 1050\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=121, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(121, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(242, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=363, out_features=363, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=363, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: mean\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 121\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 2\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 225311\n",
            "Start from epoch 0\n",
            "GPU Mem: [1152]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 1152\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Before propagation: torch.Size([7650, 121])\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv.yaml\n",
            "After propagation: torch.Size([7650, 121])\n",
            "Before propagation: torch.Size([7650, 242])\n",
            "After propagation: torch.Size([7650, 242])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x484 and 363x363)\n",
            "Load: 7.987s, Before split: 0.001084s, Split: 0.006722s, After split: 0.005518s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=73, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(73, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(146, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(219, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(292, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=365, out_features=365, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=365, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: add\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 73\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 4\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 190977\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 73])\n",
            "Load: 7.868s, Before split: 0.001082s, Split: 0.0101s, After split: 0.0006082s\n",
            "After propagation: torch.Size([7650, 73])\n",
            "Before propagation: torch.Size([7650, 146])\n",
            "After propagation: torch.Size([7650, 146])\n",
            "Before propagation: torch.Size([7650, 292])\n",
            "After propagation: torch.Size([7650, 292])\n",
            "Before propagation: torch.Size([7650, 584])\n",
            "After propagation: torch.Size([7650, 584])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x1168 and 365x365)\n",
            "Load: 8.269s, Before split: 0.001138s, Split: 0.01732s, After split: 0.000592s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=73, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(73, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(146, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(219, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(292, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=365, out_features=365, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=365, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: max\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 73\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 4\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 190977\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 73])\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=73, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(73, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(146, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(219, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(292, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=365, out_features=365, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=365, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: mean\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 73\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 4\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 190977\n",
            "Start from epoch 0\n",
            "After propagation: torch.Size([7650, 73])\n",
            "Before propagation: torch.Size([7650, 146])\n",
            "After propagation: torch.Size([7650, 146])\n",
            "Before propagation: torch.Size([7650, 292])\n",
            "After propagation: torch.Size([7650, 292])\n",
            "Before propagation: torch.Size([7650, 584])\n",
            "After propagation: torch.Size([7650, 584])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "Load: 8.754s, Before split: 0.002949s, Split: 0.007023s, After split: 0.0006156s\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x1168 and 365x365)\n",
            "Before propagation: torch.Size([7650, 73])\n",
            "After propagation: torch.Size([7650, 73])\n",
            "Before propagation: torch.Size([7650, 146])\n",
            "After propagation: torch.Size([7650, 146])\n",
            "Before propagation: torch.Size([7650, 292])\n",
            "After propagation: torch.Size([7650, 292])\n",
            "Before propagation: torch.Size([7650, 584])\n",
            "After propagation: torch.Size([7650, 584])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x1168 and 365x365)\n",
            "Load: 8.691s, Before split: 0.00572s, Split: 0.005472s, After split: 0.0007284s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=52, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(52, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(104, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(156, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(208, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block4): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(260, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block5): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(312, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=364, out_features=364, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=364, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: add\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 52\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 6\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 174573\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 52])\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=52, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(52, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(104, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(156, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(208, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block4): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(260, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block5): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(312, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=364, out_features=364, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=364, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: max\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 52\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 6\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 174573\n",
            "Start from epoch 0\n",
            "After propagation: torch.Size([7650, 52])\n",
            "Before propagation: torch.Size([7650, 104])\n",
            "After propagation: torch.Size([7650, 104])\n",
            "Before propagation: torch.Size([7650, 208])\n",
            "After propagation: torch.Size([7650, 208])\n",
            "Before propagation: torch.Size([7650, 416])\n",
            "After propagation: torch.Size([7650, 416])\n",
            "Before propagation: torch.Size([7650, 832])\n",
            "After propagation: torch.Size([7650, 832])\n",
            "Before propagation: torch.Size([7650, 1664])\n",
            "After propagation: torch.Size([7650, 1664])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "Before propagation: torch.Size([7650, 52])\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x3328 and 364x364)\n",
            "After propagation: torch.Size([7650, 52])\n",
            "Before propagation: torch.Size([7650, 104])\n",
            "After propagation: torch.Size([7650, 104])\n",
            "Before propagation: torch.Size([7650, 208])\n",
            "After propagation: torch.Size([7650, 208])\n",
            "Before propagation: torch.Size([7650, 416])\n",
            "After propagation: torch.Size([7650, 416])\n",
            "Before propagation: torch.Size([7650, 832])\n",
            "After propagation: torch.Size([7650, 832])\n",
            "Before propagation: torch.Size([7650, 1664])\n",
            "After propagation: torch.Size([7650, 1664])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x3328 and 364x364)\n",
            "GPU Mem: [2]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 2\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 1.102s, Before split: 0.0006301s, Split: 0.0005805s, After split: 0.0004206s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=52, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(52, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(104, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(156, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(208, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block4): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(260, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block5): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(312, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=364, out_features=364, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=364, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: mean\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 52\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 6\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 174573\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 52])\n",
            "After propagation: torch.Size([7650, 52])\n",
            "Before propagation: torch.Size([7650, 104])\n",
            "After propagation: torch.Size([7650, 104])\n",
            "Before propagation: torch.Size([7650, 208])\n",
            "After propagation: torch.Size([7650, 208])\n",
            "Before propagation: torch.Size([7650, 416])\n",
            "After propagation: torch.Size([7650, 416])\n",
            "Before propagation: torch.Size([7650, 832])\n",
            "After propagation: torch.Size([7650, 832])\n",
            "Before propagation: torch.Size([7650, 1664])\n",
            "After propagation: torch.Size([7650, 1664])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x3328 and 364x364)\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv.yaml\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv.yaml\n",
            "GPU Mem: [2]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 2\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "GPU Mem: [2]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 2\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 8.773s, Before split: 0.01119s, Split: 0.009523s, After split: 0.0006549s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=121, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(121, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(242, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=363, out_features=363, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=363, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: add\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 121\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 2\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 225311\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 121])\n",
            "After propagation: torch.Size([7650, 121])\n",
            "Before propagation: torch.Size([7650, 242])\n",
            "After propagation: torch.Size([7650, 242])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x484 and 363x363)\n",
            "GPU Mem: [526]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 526\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "GPU Mem: [526]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 526\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 8.424s, Before split: 0.001062s, Split: 0.006989s, After split: 0.0005884s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=121, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(121, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(242, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=363, out_features=363, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=363, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: max\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 121\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 2\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 225311\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 121])\n",
            "After propagation: torch.Size([7650, 121])\n",
            "GPU Mem: [830]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 830\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "Before propagation: torch.Size([7650, 242])\n",
            "After propagation: torch.Size([7650, 242])\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x484 and 363x363)\n",
            "GPU Mem: [1050]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 1050\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "GPU Mem: [1050]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 1050\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 9.565s, Before split: 0.009156s, Split: 0.004398s, After split: 0.0006814s\n",
            "Job launched: configs/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv.yaml\n",
            "GPU Mem: [536]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 536\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 8.879s, Before split: 0.01246s, Split: 0.003294s, After split: 0.002203s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=121, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(121, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(242, 121)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=363, out_features=363, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=363, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: mean\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 121\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 2\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=2-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 225311\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 121])\n",
            "After propagation: torch.Size([7650, 121])\n",
            "Before propagation: torch.Size([7650, 242])\n",
            "After propagation: torch.Size([7650, 242])\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=73, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(73, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(146, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(219, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(292, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=365, out_features=365, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=365, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: add\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 73\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 4\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 190977\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 73])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x484 and 363x363)\n",
            "After propagation: torch.Size([7650, 73])\n",
            "Before propagation: torch.Size([7650, 146])\n",
            "After propagation: torch.Size([7650, 146])\n",
            "Before propagation: torch.Size([7650, 292])\n",
            "After propagation: torch.Size([7650, 292])\n",
            "Before propagation: torch.Size([7650, 584])\n",
            "After propagation: torch.Size([7650, 584])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x1168 and 365x365)\n",
            "Load: 8.065s, Before split: 0.001289s, Split: 0.01132s, After split: 0.0006266s\n",
            "Load: 7.562s, Before split: 0.001055s, Split: 0.01785s, After split: 0.000592s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=73, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(73, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(146, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(219, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(292, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=365, out_features=365, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=365, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: max\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 73\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 4\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 190977\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 73])\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=73, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(73, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(146, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(219, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(292, 73)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=365, out_features=365, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=365, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: mean\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 73\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 4\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=4-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 190977\n",
            "Start from epoch 0\n",
            "After propagation: torch.Size([7650, 73])\n",
            "Before propagation: torch.Size([7650, 146])\n",
            "After propagation: torch.Size([7650, 146])\n",
            "Before propagation: torch.Size([7650, 292])\n",
            "After propagation: torch.Size([7650, 292])\n",
            "Before propagation: torch.Size([7650, 584])\n",
            "After propagation: torch.Size([7650, 584])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "Before propagation: torch.Size([7650, 73])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x1168 and 365x365)\n",
            "Load: 8.868s, Before split: 0.00126s, Split: 0.01718s, After split: 0.0006223s\n",
            "After propagation: torch.Size([7650, 73])\n",
            "Before propagation: torch.Size([7650, 146])\n",
            "After propagation: torch.Size([7650, 146])\n",
            "Before propagation: torch.Size([7650, 292])\n",
            "After propagation: torch.Size([7650, 292])\n",
            "Before propagation: torch.Size([7650, 584])\n",
            "After propagation: torch.Size([7650, 584])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x1168 and 365x365)\n",
            "Load: 8.361s, Before split: 0.0011s, Split: 0.0014s, After split: 0.0006309s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=52, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(52, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(104, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(156, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(208, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block4): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(260, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block5): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(312, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=364, out_features=364, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=364, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: add\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 52\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 6\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=add-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 174573\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 52])\n",
            "After propagation: torch.Size([7650, 52])\n",
            "Before propagation: torch.Size([7650, 104])\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=52, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(52, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(104, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(156, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(208, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block4): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(260, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block5): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(312, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=364, out_features=364, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=364, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "After propagation: torch.Size([7650, 104])\n",
            "Before propagation: torch.Size([7650, 208])\n",
            "After propagation: torch.Size([7650, 208])\n",
            "Before propagation: torch.Size([7650, 416])\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: max\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 52\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 6\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=max-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 174573\n",
            "Start from epoch 0\n",
            "After propagation: torch.Size([7650, 416])\n",
            "Before propagation: torch.Size([7650, 832])\n",
            "After propagation: torch.Size([7650, 832])\n",
            "Before propagation: torch.Size([7650, 1664])\n",
            "After propagation: torch.Size([7650, 1664])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x3328 and 364x364)\n",
            "Before propagation: torch.Size([7650, 52])\n",
            "After propagation: torch.Size([7650, 52])\n",
            "Before propagation: torch.Size([7650, 104])\n",
            "After propagation: torch.Size([7650, 104])\n",
            "Before propagation: torch.Size([7650, 208])\n",
            "After propagation: torch.Size([7650, 208])\n",
            "Before propagation: torch.Size([7650, 416])\n",
            "After propagation: torch.Size([7650, 416])\n",
            "Before propagation: torch.Size([7650, 832])\n",
            "After propagation: torch.Size([7650, 832])\n",
            "Before propagation: torch.Size([7650, 1664])\n",
            "After propagation: torch.Size([7650, 1664])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x3328 and 364x364)\n",
            "GPU Mem: [2]\n",
            "GPU Prob: [1.]\n",
            "Random select GPU, select GPU 0 with mem: 2\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:241: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_transform):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/data/dataset.py:249: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  if osp.exists(f) and torch.load(f) != _repr(self.pre_filter):\n",
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/io/fs.py:214: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location)\n",
            "Load: 1.409s, Before split: 0.0006745s, Split: 0.000555s, After split: 0.0004814s\n",
            "GNN(\n",
            "  (preprocess): Preprocess(\n",
            "    node_feature: dim_out=745\n",
            "    Total: dim_out=745\n",
            "  )\n",
            "  (pre_mp): GeneralMultiLayer(\n",
            "    (Layer_0): GeneralLayer(\n",
            "      (layer): Linear(\n",
            "        (model): Linear(in_features=745, out_features=52, bias=True)\n",
            "      )\n",
            "      (post_layer): Sequential(\n",
            "        (0): PReLU(num_parameters=1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mp): GNNSkipStage(\n",
            "    (block0): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(52, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block1): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(104, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block2): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(156, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block3): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(208, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block4): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(260, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (block5): GNNSkipBlock(\n",
            "      (f): Sequential(\n",
            "        (0): GeneralLayer(\n",
            "          (layer): LightGCNConv(312, 52)\n",
            "          (post_layer): Sequential()\n",
            "        )\n",
            "      )\n",
            "      (act): PReLU(num_parameters=1)\n",
            "    )\n",
            "  )\n",
            "  (post_mp): GNNNodeHead(\n",
            "    (layer_post_mp): MLP(\n",
            "      (model): Sequential(\n",
            "        (0): GeneralMultiLayer(\n",
            "          (Layer_0): GeneralLayer(\n",
            "            (layer): Linear(\n",
            "              (model): Linear(in_features=364, out_features=364, bias=True)\n",
            "            )\n",
            "            (post_layer): Sequential(\n",
            "              (0): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): Linear(\n",
            "          (model): Linear(in_features=364, out_features=8, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "bn:\n",
            "  eps: 1e-05\n",
            "  mom: 0.1\n",
            "cfg_dest: config.yaml\n",
            "custom_metrics: []\n",
            "dataset:\n",
            "  augment_feature: []\n",
            "  augment_feature_dims: []\n",
            "  augment_feature_repr: position\n",
            "  augment_label: \n",
            "  augment_label_dims: 0\n",
            "  cache_load: False\n",
            "  cache_save: False\n",
            "  dir: ./datasets\n",
            "  edge_dim: 128\n",
            "  edge_encoder: False\n",
            "  edge_encoder_bn: True\n",
            "  edge_encoder_name: Bond\n",
            "  edge_message_ratio: 0.8\n",
            "  edge_negative_sampling_ratio: 1.0\n",
            "  edge_train_mode: all\n",
            "  encoder: True\n",
            "  encoder_bn: True\n",
            "  encoder_dim: 128\n",
            "  encoder_name: db\n",
            "  format: PyG\n",
            "  label_column: none\n",
            "  label_table: none\n",
            "  location: local\n",
            "  name: AmazonPhoto\n",
            "  node_encoder: False\n",
            "  node_encoder_bn: True\n",
            "  node_encoder_name: Atom\n",
            "  remove_feature: False\n",
            "  resample_disjoint: False\n",
            "  resample_negative: False\n",
            "  shuffle_split: True\n",
            "  split: [0.8, 0.2]\n",
            "  split_mode: random\n",
            "  task: node\n",
            "  task_type: classification\n",
            "  to_undirected: False\n",
            "  transductive: True\n",
            "  transform: none\n",
            "  tu_simple: True\n",
            "device: cuda:0\n",
            "example_arg: example\n",
            "example_group:\n",
            "  example_arg: example\n",
            "gnn:\n",
            "  act: prelu\n",
            "  agg: mean\n",
            "  att_final_linear: False\n",
            "  att_final_linear_bn: False\n",
            "  att_heads: 1\n",
            "  batchnorm: False\n",
            "  clear_feature: True\n",
            "  dim_inner: 52\n",
            "  dropout: 0.0\n",
            "  flow: source_to_target\n",
            "  head: node\n",
            "  keep_edge: 0.5\n",
            "  l2norm: True\n",
            "  layer_type: lightgcnconv\n",
            "  layers_mp: 6\n",
            "  layers_post_mp: 2\n",
            "  layers_pre_mp: 1\n",
            "  msg_direction: single\n",
            "  normalize_adj: False\n",
            "  self_msg: concat\n",
            "  skip_every: 1\n",
            "  stage_type: skipconcat\n",
            "gpu_mem: False\n",
            "mem:\n",
            "  inplace: False\n",
            "metric_agg: argmax\n",
            "metric_best: auto\n",
            "model:\n",
            "  edge_decoding: dot\n",
            "  graph_pooling: add\n",
            "  loss_fun: cross_entropy\n",
            "  match_upper: True\n",
            "  size_average: mean\n",
            "  thresh: 0.5\n",
            "  type: gnn\n",
            "num_threads: 6\n",
            "num_workers: 0\n",
            "optim:\n",
            "  base_lr: 0.01\n",
            "  lr_decay: 0.1\n",
            "  max_epoch: 400\n",
            "  momentum: 0.9\n",
            "  optimizer: adam\n",
            "  scheduler: cos\n",
            "  steps: [30, 60, 90]\n",
            "  weight_decay: 0.0005\n",
            "out_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv\n",
            "print: both\n",
            "round: 4\n",
            "run_dir: results/AmazonPhoto_grid_AmazonPhoto_Metrics/AmazonPhoto-format=PyG-dataset=AmazonPhoto-task=node-trans=True-feature=-label=-l_pre=1-l_mp=6-l_post=2-stage=skipconcat-agg=mean-layer=lightgcnconv/0\n",
            "seed: 1\n",
            "share:\n",
            "  dim_in: 745\n",
            "  dim_out: 8\n",
            "  num_splits: 2\n",
            "tensorboard_agg: True\n",
            "tensorboard_each_run: False\n",
            "train:\n",
            "  auto_resume: False\n",
            "  batch_size: 32\n",
            "  ckpt_clean: True\n",
            "  ckpt_period: 100\n",
            "  enable_ckpt: True\n",
            "  epoch_resume: -1\n",
            "  eval_period: 20\n",
            "  iter_per_epoch: 32\n",
            "  mode: standard\n",
            "  neighbor_sizes: [20, 15, 10, 5]\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "  skip_train_eval: False\n",
            "  walk_length: 4\n",
            "val:\n",
            "  node_per_graph: 32\n",
            "  radius: extend\n",
            "  sample_node: False\n",
            "  sampler: full_batch\n",
            "view_emb: False\n",
            "Num parameters: 174573\n",
            "Start from epoch 0\n",
            "Before propagation: torch.Size([7650, 52])\n",
            "After propagation: torch.Size([7650, 52])\n",
            "Before propagation: torch.Size([7650, 104])\n",
            "After propagation: torch.Size([7650, 104])\n",
            "Before propagation: torch.Size([7650, 208])\n",
            "After propagation: torch.Size([7650, 208])\n",
            "Before propagation: torch.Size([7650, 416])\n",
            "After propagation: torch.Size([7650, 416])\n",
            "Before propagation: torch.Size([7650, 832])\n",
            "After propagation: torch.Size([7650, 832])\n",
            "Before propagation: torch.Size([7650, 1664])\n",
            "After propagation: torch.Size([7650, 1664])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/GraphGym/run/main.py\", line 50, in <module>\n",
            "    train(loggers, loaders, model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 71, in train\n",
            "    train_epoch(loggers[0], loaders[0], model, optimizer, scheduler)\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/train.py\", line 18, in train_epoch\n",
            "    pred, true = model(batch)\n",
            "                 ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/gnn.py\", line 182, in forward\n",
            "    batch = module(batch)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/head.py\", line 33, in forward\n",
            "    batch = self.layer_post_mp(batch)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 150, in forward\n",
            "    batch.node_feature = self.model(batch.node_feature)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 78, in forward\n",
            "    batch = layer(batch)\n",
            "            ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 43, in forward\n",
            "    batch = self.layer(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/GraphGym/graphgym/models/layer.py\", line 91, in forward\n",
            "    batch = self.model(batch)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (7650x3328 and 364x364)\n",
            "Results aggregated across models saved in results/AmazonPhoto_grid_AmazonPhoto_Metrics/agg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd analysis\n",
        "!jupyter notebook\n",
        "!example.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYhlCVy0Cd4v",
        "outputId": "afff17e7-a411-4580-ee74-27f8a4dae4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: analysis: No such file or directory\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/usr/local/etc/jupyter/jupyter_notebook_config.d/ipyparallel.json\n",
            "    \t/usr/local/etc/jupyter/jupyter_notebook_config.d/panel-client-jupyter.json\n",
            "    \t/usr/local/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/usr/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/root/.local/etc/jupyter/jupyter_notebook_config.json\n",
            "|DEBUG|Paths used for configuration of jupyter_notebook_config: \n",
            "    \t/root/.jupyter/jupyter_notebook_config.json\n",
            "\n",
            "  _   _          _      _\n",
            " | | | |_ __  __| |__ _| |_ ___\n",
            " | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "  \\___/| .__/\\__,_\\__,_|\\__\\___|\n",
            "       |_|\n",
            "                       \n",
            "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions.\n",
            "\n",
            "https://jupyter-notebook.readthedocs.io/en/latest/migrate_to_notebook7.html\n",
            "\n",
            "Please note that updating to Notebook 7 might break some of your extensions.\n",
            "\n",
            "|INFO|google.colab serverextension initialized.\n",
            "|INFO|Loading IPython parallel extension\n",
            "|INFO|Serving notebooks from local directory: /content\n",
            "|INFO|Jupyter Notebook 6.5.5 is running at:\n",
            "|INFO|http://localhost:8888/?token=b682268799ef0fcac83bba20e30e426f357ee5f5d41bb61a\n",
            "|INFO| or http://127.0.0.1:8888/?token=b682268799ef0fcac83bba20e30e426f357ee5f5d41bb61a\n",
            "|INFO|Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
            "|CRITICAL|\n",
            "    \n",
            "    To access the notebook, open this file in a browser:\n",
            "        file:///root/.local/share/jupyter/runtime/nbserver-9857-open.html\n",
            "    Or copy and paste one of these URLs:\n",
            "        http://localhost:8888/?token=b682268799ef0fcac83bba20e30e426f357ee5f5d41bb61a\n",
            "     or http://127.0.0.1:8888/?token=b682268799ef0fcac83bba20e30e426f357ee5f5d41bb61a\n",
            "|CRITICAL|received signal 2, stopping\n",
            "|INFO|interrupted\n",
            "|INFO|Shutting down 0 kernels\n",
            "|INFO|Shutting down 0 terminals\n",
            "/bin/bash: line 1: example.ipynb: command not found\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}